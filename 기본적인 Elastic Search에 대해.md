[ID: 45]
		[Tags: OPS PROJECTS]
		[Title: 기본적인 Elastic Search에 대해]
		[WriteTime: ]
		[ImageNames: ]
		
		엘라스틱서치에서 다루는 데이터를 도큐먼트라고 한다.

도큐먼트는 RDBME의 레코드와 대응되는 개념이다.

도큐먼트에는 필드들이 존재하고, 이 필드들은 애트리뷰트(컬럼)과 대응되는 개념이다.

도큐먼트는 JSON 형식인 Query DSL을 통해 작성된다.

도큐먼트에

```yaml
{
	"name": "choigonyok",
	"age": 26
}
```


이라고 저장했다면, 실제 도큐먼트는 이 데이터와 관련한 여러 메타데이터들과 함께 저장된다.

```yaml
{
	...
	"_index": "user",
	"_id": "123",
	"_version": 1,
	"_source": {
	"name": "choigonyok",
	"age": 26,
	}
}
```


엘라스틱서치에서 쿼리는 rest API를 통해 질의된다.

모든 도큐먼트는 위 예시의 "_index"처럼 특정 인덱스에 포함되어있고, 논리적으로 연관되어있는 데이터끼리 같은 인덱스로 묶인다. 인덱스는 DB처럼 검색 속도를 빠르게 하기 위한 것이다.

## ELK스택


키바나는 분석 및 시각화 플랫폼으로 데이터를 대시보드를 통해 시각화시켜주는 도구이다.

변화감지 및 예측도 할 수 있다.

로그스태시는 어플리케이션의 일지를 처리하고 엘라스틱서치로 전달하는 도구이다.

데이터 처리 파이프라인을 구성하는 게 일반적이다. 입력을 받아서 필터로 처리하고 출력으로 타겟에 전달한다.

예를 들어 로그가 생성되면, 로그을 읽고 메서드별로, IP별로, 상태코드별로, 시간별로 분리해서 각각 필요한 곳에 전달할 수 있다.

이런식으로 분리해서 엘라스틱서치에 저장하면 엘라스틱서치는 필드별로 쿼리를 수행할 수 있게되고, 메서드가 GET인 로그를 검색했을 떄 결과가 출력될 수 있게 된다.

X-Pack는 ELK스택에 리소스 모니터링, 접근제어 및 역할 설정, 알람, PDF, CSV로 레포트 생성 등의 기능을 더해주는 도구이다.

Beats는 경량화된 에이전드이다. 데이터를 수집하고 전달한다. 파일비트는 로그파일등에서 데이터를 수집하고 메트릭비트는 리소스 사용량등에 대한 데이터를 수집한다. 이외에도 여러 비트들이 있다.

##  아키텍처


http요청을 통해 조회 쿼리를 수행하는데, 보통 라이브러리를 통해서 하게된다.

조회가 아닌 데이터 수정이 일어나면 DB와 동기화를 시켜줘야한다. 한 번 데이터가 변경될 때 DB와 엘라스틱서치 모두에 두 번 변경해야하기 때문에 불필요해보이긴 하다.

데이터 일부 수정을 할 떄는 agent를 통해 엘라스틱서치에 데이터를 보내서 변경할 수도 있다.

ES는 노드 단위로 데이터를 저장한다. 하나의 머신에서 여러 노드를 실행할 수 있다.

클러스터는 여러 노드의 집합이다.

여러 클러스터를 통해 클러스터마다 다른 설정과 논리적인 분리를 할 수 있지만 보통 한개로 충분하다.

노드가 새롭게 시작되면 기존 클러스터에 포함되거나 스스로 독립적인 클러스터를 만들게 된다.

여러 노드를 통해 확장성과 유연성을 보장할 수 있다.

Dev tools를 통해 여러 쿼리를 날려볼 수 있다. indices는 인덱스와 관련한 모니터링, 관리에 사용된다.

인덱스는 각각 하나 이상의 샤드로 나누어지고, 각 샤드는 클러스터 내의 여러 노드에 분산저장된다.

샤드(shard)는 데이터를 분산 저장하고 검색할 때 병렬로 검색해서 빠른 성능을 보장하기 위한 논리적인 파티션의 기본 단위이다.

각 샤드는 독립적으로 검색 및 색인 작업을 수행할 수 있다.

샤드는 프라이머리 샤드와 레플리카 샤드로 구분되는데, 레플리카 샤드는 프라이머리 샤드에 복제본으로 고가용성과 안정성을 위해 사용되고, 백업역할도 한다.

하나의 도큐먼트를 필드별로 나눠서 샤드가 저장하는게 아니라, 같은 student라는 필드를 가진 여러 데이터들이 있을 때 인덱스의 탐색키가 age라면 샤드1, 2, 3이 각 도큐먼트를 나눠서 다른 노드에 저장하고, 사용자가 만약 전체 student에 대한 정보를 필요로 할 때 샤드 1,2,3이 병렬로 데이터를 가져오면서 3배의 성능향상을 낼 수 있으며, 만약 샤드1이 담당하는 데이터만 필요로하는 경우 샤드 2,3은 일하지않고 샤드 1만 데이터를 불러옴으로써 불필요한 오버헤드를 줄일 수 있다

샤드는 인덱스의 조각을 의미한다.

샤딩을 통해 여러 노드들의 리소스가 하나의 클러스터를 위해 사용될 수 있고,

샤딩으로 병렬 쿼리 처리가 가능해진다.

샤드 하나당 20억개의 데이터를 담당할 수 있고, 각 샤드는 여러 노드에 분산 배치될 수 있다.

기존에 샤드는 디폴트로 5개가 생성되고, 데이터 규모가 적다면 샤드 수를 조정할 수 있었다.

이후에 샤드는 하나로 변경되었고 Split API를 통해 샤드 수를 늘리거나 Shrink API를 통해 샤드 수를 줄일 수 있다.

###  Replication


샤드를 사용해서 확장성을 보장해도 샤드가 저장된 노드에 장애가 생기면 데이터는 그대로 사라진다. ES는 샤드의 replication을 지원한다. 복제된 샤드를 replica shard라고 부르고, 메인 샤드를 primary shard라고 부른다.

장애를 대비하기 위한 replica shard인만큼 primary shard와 같은 노드에 배치되어서는 안된다. 그럼 의미가 없다. 따라서 노드가 하나인 클러스터에서 replication을 적용하는 것은 의미가 없다고 볼 수 있다.

replication은 고가용성 보장 뿐만 아니라 로드밸런싱을 위해서도 사용될 수 있다. ES는 서로 다른 샤드를 활용한 병렬 쿼리 처리 뿐만 아니라 하나의 샤드의 replica 에서도 CPU의 멀티쓰레딩을 활용한 병렬처리를 지원한다.

index 생성은 PUT /{INDEX_NAME} 으로 생성이 가능하다.

인덱스를 생성하면 default로 primary/replica shard가 각각 하나씩 생성된다. 노드가 하나면 replica shard가 배포될 다른 노드가 없기 때문에 status가 yellow로 표시될 수 있다. 이 경우 노드를 추가해주면 해결가능하고, yellow라고 해서 오류인 것은 아니고 warning에 가깝다고 볼 수 있다.

default 인덱스의 샤드들은 rep이 0으로 표시되어있지만, 이건 노드를 추가하면 알아서 rep이 1로 변경되면서 default 인덱스의 샤드들의 replication이 생성되어 새로운 노드에 배치되게 된다.

###  Snapshot


스냅샷으로 특정 시점의 인덱스 데이터를 백업할 수 있다. 파일형태로 내보내고 원하면 해당 파일을 통해 롤백할 수 있다.

### 개발환경에서의 노드 추가


마스터노드에서 bin/elasticsearch-create-enrollment-token --scope node로 토큰을 생성하고, 해당 토큰값을 등록해서 새로운 노드를 실행해주면된다. 처음 ES를 실행할 때 생성된 토큰을 사용해도 되는데 만료시간이 30분인 것을 참고해야한다.

컨테이너가 아닌 직접 패키지를 다운로드해서 설치하는 경우에는 설치한 후 bin/elasticsearch --enrollment-token {TOKEN}으로 ES를 실행하면 되지만, 컨테이너 환경에서는 컨테이너를 실행할 때 ES가 함께 실행되어버리기 때문에 컨테이너를 생성한 이후 다시 bin/elasticsearch 커맨드를 입력하게되면 재시작을 위해 종료되고, 재시작은 되지 않게 된다.

따라서 환경변수로 컨테이너를 실행할 때 토큰을 등록해주어야한다.

docker run --name es02 --net elastic -p 9201:9200 -it -m 3GB -e "ENROLLMENT_TOKEN={TOKEN}" docker.elastic.co/elasticsearch/elasticsearch:8.11.3

![image](https://res.craft.do/user/full/6deb5b3a-d995-5f97-e85b-e7c3c5f9702a/doc/0EFB76FE-D3CD-41EB-8A53-019854C704EE/85C4A8F6-595F-4A58-A539-FCD957FCC641_2/LIpiBdvzcakp3JhJvNZ3wVDxSoZflgUTgLeGfF7Dlkoz/Image.png)

그럼 노드가 추가되면서 pages 레플리카 샤드가 새로운 노드에 배치되었기 때문에 yello status에서 green으로 변경되게 되고, number_of_nodes도 2로 변경된 것을 확인할 수 있다.

![image](https://res.craft.do/user/full/6deb5b3a-d995-5f97-e85b-e7c3c5f9702a/doc/0EFB76FE-D3CD-41EB-8A53-019854C704EE/66735B14-E620-4995-A122-E115C2A06F46_2/o1pyAm8uPLRiJGe6yT5hJ00sPfNY5awPq9ee4TkeyDQz/Image.png)

기존의 default 인덱스들도 살펴보면 0이었던 rep이 1로 변경되며 replication을 사용하게 된다.

이러한 방식으로 클러스터에 노드를 추가하는 것은 운영환경용이 아니라 개발환경을 위해 간단히 생성하는 방식이다.

운영환경에서 노드를 추가하는 방식이 다르고 더 복잡한 이유?

노드를 추가하게되면 클러스터의 전체 shard 수가 늘어나게 된다. ES는 특정 해시 함수와 shard 수를 사용해서 도큐먼트가 어느 샤드에 저장되는지를 결정하게 된다. 이를 라우팅이라고 한다.

만약 샤드 수가 2인 상태로 도큐먼트를 저장해서 샤드B에 도큐먼트가 저장되었다고 가정하자. 이후에 샤드 수를 5개로 증가시키고, 같은 도큐먼트를 조회하려고 하면 ES는 샤드B가 아닌 다른 샤드를 참조할 수도 있게된다. 샤드 수가 달라져서 도큐먼트를 찾는 함수값이 달라졌기 때문이다.

###  Read


만약 데이터 조회 요청이 오면, 노드는 라우팅(해시함수를 기반으로한 샤드 선정)을 통해 여러개의 replication 그룹 중 하나를 선정한다.

그리고 ARS(Adaptive Replica Selection)을 통해 해당 replication 그룹(primary shard + replica shards) 중 하나의 샤드를 선정한다. 이 때 ARS로 인해 여러 샤드 중 가장 성능이 빠른 샤드를 ES가 알아서 선택한다.

###  Write


만약 데이터 변경 요청이 오면 노드는 라우팅을 통해 여러 primary shard 중 하나를 선정한다. replica shard는 읽기 전용이기 때문에 사용할 수 없다. primary shard에 데이터를 쓰면 primary shard가 자신과 연관된 모든 replica shard들에게 변경된 데이터를 적용시킨다.

만약 레플리케이션 과정에서 장애가 발생해서 일부 replica shard에게만 데이터가 전송되었다면 어떻게 해야할까? 이 상황을 해결하기 위해 primary term과 sequence number을 사용한다.

primary term은 primary shard가 몇 번 바뀌었는지가 저장되어있다. primary shard가 변경되어야하면 

sequence number는 작업이 몇 번 수행되었는지를 저장하고있다. auto increment 방식으로 1씩 계속 증가한다.

##  Versioning


버전은 internal, external 두 종류가 있고, 버전을 지정하기 위해서는 버전 넘버와 버전 타입을 명시해야한다.

근데 실제 버전관리를 위해서보다는 동시성 제어 최적화를 위해서 사용되는 경우가 더 많다.

두 사용자가 같은 한 계좌에서 동시에 만원을 출금한다고 가정하자. RDBMS의 트랜잭션 같은 고립성을 제공하는 기능이 따로 있지 않기 때문에, 두 명이 만원을 출금했음에도 계좌에서는 만원만 출금된 것으로 기록될 수 있다.

따라서 데이터를 변경할 때 버전을 명시해서 조회했을 떄와 데이터를 변경하려고 할 때의 버전이 다르다면 그 사이 다른 클라이언트가 데이터를 변경했음을 확인할 수 있게된다.

마찬가지로 primary term과 sequence number를 사용해서도 동시성을 제어할 수 있다.

그럼 데이터가 이미 변경됐다는 건 확인할 수 있겠는데, 그 상황을 어떻게 처리해야할까?

최신 primary term과 sequence number를 확인하기 위해 도큐먼트를 다시 조회해서 해당 값으로 다시 요청을 보내야한다.

이론적으로는 계속 동시적인 다른 요청에 의해 이 요청을 무한히 원하는 작업을 못하게 될 수도 있긴 하다.

운영환경에서 쿠버네티스를 사용한다면 ELK스택도 별도의 쿠버네티스 클러스터에 구축하는 것이 좋은 것 같다. 만약 노드 3개가 순차적으로 죽고있는데 관리자가 알아채지 못한다면 replication을 통해 2번까지는 버틸 수 있지만 3번은 버티지 못한다.

쿠버네티스에 파드로 배치하면 하나가 죽고 다른 replica가 역할을 감당하는 중에 다시 redeploy되면서 3개의 파드를 유지할 수 있게되고, 훨씬 더 안정적인 방식일 수 있겠다는 생각을 했다.

### Role


master : 마스터노드의 역할

data : 데이터 저장과 쿼리, 데이터의 수정 등을 담당한다. 일반적으로 대부분의 노드는 이 역할을 갖는다. data role을 비활성화하면 master 노드를 위한 전용 standby 노드로 활용될 수 있다.

ingest : ingest 파이프라인의 실행을 담당한다. 로그스태시의 간소화 버전인데, 데이터(도큐먼트)가 저장되기 전에 이 ingest 노드에서 데이터의 변환이나 필드 수정 등을 할 수 있게된다.

coordination : 쿼리를 분산시키는 역할을 한다. 이 역할을 가진 노드는 data 역할을 갖지 못해서 쿼리 처리를 하지 못한다. 그저 요청 분산만 한다.

GET /_cat/nodes?v 쿼리를 통해 노드들과 노드들의 역할을 확인할 수 있다.

도큐먼트 ID를 랜덤 생성 uuid가 아닌 사용자 지정으로 생성하고 싶을 때는 POST대신 PUT을 통해 가능하다.

```yaml
PUT /products/_doc/100
{
  "name": "test name2",
  "price": 1000,
  "stock": 100
}
```


만약 도큐먼트가 있는지 확인하고 있으면 특정 작업 수행, 없다면 새 도큐먼트를 생성하도록 하는 방식은 일반적으로는 두 작업을 수행해야한다. 그런데 upsert를 사용하면 하나의 요청에서 이를 구현할 수 있다.

### Script


스크립트는 요청에 대한 조건이나 수행 등을 프로그래밍 언어처럼 설정할 수 있는 요청의 한 부분이다.

```yaml
POST /products/_update/100
{
  "script": {  
    "source": """  
    if (ctx._source.stock <= 0) {  
      ctx.op = \'noop\';  
    }  
    ctx._source.stock -= params.quantity;  
    """,  
    "params": {  
      "quantity": 5  
    }
  }
}
```


이렇게 하면 stock이 5씩 줄어들다가 0보다 작거나 같아지게 되면 이 요청을 수행하지 않는다. 만약 ctx.op가 noop이 아닌 delete로 설정되어있으면 이 조건에 맞을 때 해당 도큐먼트를 삭제하게 된다.

ES로 쿼리를 요청할 때 HTTP Content-Type 헤더는 application/x-ndjson으로 요청해야한다. application/json도 요청이 가능하긴 하지만 정석은 아니다.

ES에서 여러 요청을 동시에 수행할 때, 데이터베이스의 트랜잭션 원자성과는 달리 하나의 요청이 실패한다고 해도 다른 요청은 정상적으로 수행될 수 있다.

그래서 요청이 실패할 경우 어떤 쿼리에서 실패한 것인지를 확인해야한다.

### 라우팅 / seq_num 과 primary_term, version을 활용한 동시성 제어 / bulk api